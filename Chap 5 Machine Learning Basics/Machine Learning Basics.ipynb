{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Chap 5 Machine Learning Basics\n",
    "\n",
    "### 5.1 Learning Algorithms\n",
    "\n",
    "#### 5.1.1 The Task, T\n",
    "\n",
    "Many kinds of tasks can be solved with machine learning. Some of the most common machine learning tasks include the following:\n",
    "- Classification\n",
    "- Classification with missing inputs\n",
    "- Regression\n",
    "- Transcription\n",
    "- Machine translation\n",
    "- Structured output\n",
    "- Anomaly detection\n",
    "- Synthesis and sampling\n",
    "- Imputation of missing values\n",
    "- Denoising\n",
    "- Density estimation or probability mass function estimation"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 5.1.2 The Performance Measure, P\n",
    "#### 5.1.3 The Experience, E\n",
    "\n",
    "Roughly speaking, __unsupervised learning__ involves observing several examples of a random vector x, and attempting to implicitly or explicitly learn the probability distribution __p(x)__, or some interesting properties of that distribution, while __supervised learning__ involves observing several examples of a random vector x and an associated value or vector y, and learning to predict y from x, usually by estimating __p(y|x)__.\n",
    "\n",
    "A __design matrix__ is a matrix containing a different example in each row. Each column of the matrix corresponds to a different feature."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 5.1.4 Example: Linear Regression\n",
    "\n",
    "Take a vector $x \\in R^n$ as input and predict the value of a scalar $y \\in R$ as its output. Let $\\hat y$ be the value that our model predicts y should take on.\n",
    "\n",
    "We define the output to be $$\\hat y = w^T x$$ where $w \\in R^n$ is a vector of parameters.\n",
    "\n",
    "One way of measuring the performance of the model is to compute the mean squared error of the model on the test set. If $\\hat y^{(test)}$ gives the predictions of the model on the test set, then the mean squared error is given by $$MSE_{test} = \\frac{1}{m} || \\hat y^{(test)} - y^{(test)}||^2_2$$\n",
    "\n",
    "Design an algorithm that will improve the weights w in a way that reduces $MSE_{test}$ when the algorithm is allowed to gain experience by observing a training set $(X^{(train)},y^{(train)})$\n",
    "\n",
    "To minimize $MSE_{train}$, we can simply solve for where its gradient is 0. \n",
    "\n",
    "\\begin{align}\n",
    "    & \\nabla_w MSE_{train} = 0 \\\\\n",
    "    \\Rightarrow & \\nabla_w \\frac{1}{m} ||\\hat y^{(train)} - y^{(train)}||^2_2 = 0 \\\\\n",
    "    \\Rightarrow & \\frac{1}{m} \\nabla_w  ||X^{(train)}w - y^{(train)}||^2_2 = 0 \\\\\n",
    "    \\Rightarrow & \\nabla_w  (X^{(train)}w - y^{(train)})^T (X^{(train)}w - y^{(train)}) = 0 \\\\\n",
    "    \\Rightarrow & 2X^{(train)^T} X^{(train)}w - 2 X^{(train)^T} y^{(train)} = 0 \\\\\n",
    "    \\Rightarrow & w = (X^{(train)^T} X^{(train)})^{-1} X^{(train)^T} y^{(train)} \\\\\n",
    "\\end{align}\n",
    "\n",
    "The system of equations is known as the __normal equations__\n",
    "\n",
    "The term __linear regression__ is often used to refer to a slightly more sophisticated model with one additional parameter - an intercept term b.\n",
    "\n",
    "$$\\hat y = w^T x + b$$"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 5.2 Capacity, Overfitting and Underfitting\n",
    "\n",
    "The ability to perform well on previously unobserved inputs is called __generalization__\n",
    "\n",
    "When training a machine learning model, we have access to a training set, we can compute some error measure on the training set called the __training error__, and we reduce this training error. So far, what we have described is simply an optimization problem.\n",
    "\n",
    "What separates machine learning from optimization is that we want the __generalization error__, also called the __test error__, to be low as well.\n",
    "\n",
    "How can we affect performance on the test set when we get to observe only the training set? The field of __statistical learning theory__ provides some answers. If the training and the test set are collected arbitrarily, there is indeed little we can do. If we are allowed to make __some assumptions__ about how the training and test set are collected, then we can make some progress.\n",
    "\n",
    "The train and test data are generated by a probability distribution over datasets called the __data generating process.__ \n",
    "\n",
    "We typically make a set of assumptions known collectively as the __i.i.d. assumptions__. \n",
    "- The examples in each dataset are __independent__ from each other\n",
    "- The train set and test set are __identically  distributed__, drawn from the same probability distribution as each other.\n",
    "\n",
    "This probabilistic framework and the __i.i.d. assumptions__ allow us to mathematically study the relationship between __training error and test error.__\n",
    "\n",
    "The expected __training error__ of a randomly selected model is equal to the expected __test error__ of that model.\n",
    "\n",
    "We sample the training set, then use it to choose the parameters to reduce training set error, then sample the test set. Under this process, _the expected test error is greater than or equal to the expected value of training error._ The factors determining how well a machine learning algorithm will perform are its ability to:\n",
    "\n",
    "- Make the training error small.\n",
    "- Make the gap between training and test error small.\n",
    "\n",
    "__Underfitting__ occurs when the model is not able to obtain a sufficiently low error value on the training set. __Overfitting__ occurs when the gap between the training error and test error is too large.\n",
    "\n",
    "We can control whether a model is more likely to overfit or underfit by altering its __capacity.__ A model’s capacity is its ability to fit a wide variety of functions. \n",
    "\n",
    "One way to control the capacity of a learning algorithm is by choosing its __hypothesis space__, the set of functions that the learning algorithm is allowed to select as being the solution.\n",
    "\n",
    "_Machine learning algorithms will generally perform best when their __capacity is appropriate__ for the true complexity of the task they need to perform and the amount of training data they are provided with._\n",
    "\n",
    "If we have more parameters than training examples. We have little chance of choosing a solution that generalizes well when so many wildly different solutions exist.\n",
    "\n",
    "Capacity is __not__ determined only by the choice of model. The model specifies which __family of functions__ the learning algorithm can choose from when varying the parameters in order to reduce a training objective. This is called the __representational capacity__ of the model.\n",
    "\n",
    "The most important results in statistical learning theory show that the discrepancy between training error and generalization error is bounded from above by a quantity that grows as the model capacity grows but shrinks as the number of training examples increases.\n",
    "\n",
    "The problem of determining the capacity of a deep learning model is especially difficult because the effective capacity is limited by the capabilities of the optimization algorithm, and we have little theoretical understanding of the very general non-convex optimization problems involved in deep learning."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 5.2.1 The No Free Lunch Theorem\n",
    "\n",
    "Learning theory claims that a machine learning algorithm can generalize well from a finite training set of examples.\n",
    "\n",
    "In part, machine learning avoids this problem by offering only probabilistic rules, rather than the entirely certain rules used in purely logical reasoning. Machine learning promises to find rules that are probably correct about most members of the set they concern.\n",
    "\n",
    "The __no free lunch theorem__ for machine learning (Wolpert, 1996) states that, averaged over all possible data generating distributions, every classification algorithm has the same error rate when classifying previously unobserved points. \n",
    "\n",
    "In other words, in some sense, __no machine learning algorithm is universally any better than any other.__ The most sophisticated algorithm we can conceive of has the same average performance __(over all possible tasks)__ as merely predicting that every point belongs to the same class.\n",
    "\n",
    "Fortunately, these results hold only when we average over all possible data generating distributions. If we make assumptions about the kinds of probability distributions we encounter in real-world applications, then we can design learning algorithms that perform well on these distributions.\n",
    "\n",
    "This means that the goal of machine learning research is __not__ to seek a __universal learning algorithm__ or the absolute best learning algorithm. Instead, our goal is to understand __what kinds of distributions are relevant to the “real world”__ that an AI agent experiences, and what kinds of machine learning algorithms perform well on data drawn from the kinds of data generating distributions we care about."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 5.2.2 Regularization\n",
    "The no free lunch theorem implies that we must design our machine learning algorithms to perform well on a specific task. We do so by building __a set of preferences__ into the learning algorithm. When these preferences are aligned with the learning problems we ask the algorithm to solve, it performs better.\n",
    "\n",
    "We can thus control the performance of our algorithms by choosing what __kind of functions__ we allow them to draw solutions from, as well as by controlling the __amount of these functions.__ We can also give a learning algorithm a preference for one solution in its hypothesis space to another. This means that both functions are eligible, but one is preferred.\n",
    "\n",
    "Modify the training criterion for linear regression to include __weight decay.__ $$J(w) = MSE_{train} + \\lambda w^Tw$$\n",
    "\n",
    "Minimizing J(w) results in a choice of weights that make a tradeoff between __fitting the training data__ and __being small__. This gives us solutions that have a smaller slope, or put weight on fewer of the features.\n",
    "\n",
    "In our weight decay example, we expressed our preference for linear functions defined with smaller weights explicitly, via an extra term in the criterion we minimize. There are many other ways of expressing preferences for different solutions, both implicitly and explicitly. Together, these different approaches are known as __regularization.__ \n",
    "\n",
    "__Regularization__ is any modification we make to a\n",
    "learning algorithm that is intended to reduce its generalization error but not its training error.\n",
    "\n",
    "The no free lunch theorem has made it clear that there is __no best machine learning algorithm__, and, in particular, __no best form of regularization.__ Instead we must choose a form of regularization that is well-suited to the particular task we want to solve."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 5.3 Hyperparameters and Validation Sets\n",
    "Most machine learning algorithms have several settings that we can use to control the behavior of the learning algorithm. These settings are called __hyperparameters.__\n",
    "\n",
    "The setting must be a hyperparameter because it is __not appropriate to learn__ that hyperparameter on the training set. This applies to all hyperparameters that __control model capacity__. If learned on the training set, such hyperparameters would always choose the __maximum possible model capacity__, resulting in __overfitting__.\n",
    "\n",
    "__Test set__, composed of examples coming from the same distribution as the training set, can be used to estimate the __generalization error__ of a learner, after the learning process has completed.\n",
    "\n",
    "It is important that the test examples are __not__ used in any way to make choices about the model, including its hyperparameters. For this reason, __no__ example from the __test set__ can be used in the __validation set.__\n",
    "\n",
    "Se split the training data into two __disjoint subsets__. One of these subsets is used to __learn the parameters__. The other subset is our validation set, used to __estimate the generalization error during or after training__, allowing for the hyperparameters to be updated accordingly.\n",
    "\n",
    "The subset of data used to __guide the selection of hyperparameters__ is called the __validation set__. Typically, one uses about __80%__ of the training data for training and __20%__ for validation.\n",
    "\n",
    "In practice, when the same test set has been used repeatedly to evaluate performance of different algorithms over many years ... we end up having optimistic evaluations with the test set as well. Benchmarks can thus become stale and then __do not reflect the true field performance__ of a trained system."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 5.3.1 Cross-Validation\n",
    "Dividing the dataset into a fixed __training set__ and a fixed __test set__ can be problematic if it results in the test set being small. A small test set implies __statistical uncertainty__ around the estimated average test error, making it difficult to claim that algorithm A works better than algorithm B on the given task.\n",
    "\n",
    "When the dataset is too small, are alternative procedures enable one to use all of the examples in the estimation of the mean test error, at the price of increased computational cost. \n",
    "\n",
    "These procedures are based on the idea of repeating the training and testing computation on different randomly chosen subsets or splits of the original dataset.\n",
    "\n",
    "__k-fold cross-validation__ procedure, in which a partition of the dataset is formed by splitting it into k non-overlapping subsets. The __test error__ may then be estimated by taking __the average test error across k trials.__"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 5.4 Estimators, Bias and Variance\n",
    "\n",
    "#### 5.4.1 Point Estimation\n",
    "__Point estimation__ is the attempt to provide the single “best” prediction of some quantity of interest.\n",
    "\n",
    "Let {x(1) , . . . , x(m) } be a set of m independent and identically distributed (i.i.d.) data points. A __point estimator__ or __statistic__ is __any function__ of the data: $$\\hat \\theta_m = g(x^{(1)}, ... , x^{(m)})$$ \n",
    "\n",
    "The definition does not require g to return a value that is close to the true $\\theta$ or even that the range of g is the same as the set of allowable values of $\\theta$. \n",
    "\n",
    "This definition of a point estimator is very __general__ and allows the designer of an estimator __great flexibility__. A __good estimator__ is a function whose output is __close to the true underlying $\\theta$__ that generated the training data."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 5.4.2 Bias \n",
    "The bias of an estimator is defined as:\n",
    "$$bias( \\hat \\theta_m) = \\mathbb{E}(\\hat \\theta_m) - \\theta$$ \n",
    "where the expectation is over the data (seen as __samples from a random variable__) and $\\theta$ is the __true underlying value of $\\theta$__ used to define the data generating distribution.\n",
    "\n",
    "An estimator $\\hat \\theta_m$ is said to be __unbiased__ if $bias(\\hat \\theta_m) = 0$, which implies that $\\mathbb{E}(\\hat \\theta_m) = \\theta$."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Example: Bias of mean estimator of Bernoulli Distribution\n",
    "Consider a set of m samples that are independently and identically distributed (i.i.d) according to a Bernoulli distribution with mean $\\theta$: \n",
    "$$P(x^{(i)};\\theta) = \\theta^{x^{(i)}} (1-\\theta)^{(1-x^{(i)})}$$\n",
    "\n",
    "A common estimator for the $\\theta$ parameter of this distribution is the __mean of the training samples__: \n",
    "$$\\hat \\theta_m = \\frac{1}{m} \\sum_{i=1}^{m} x^{(i)} $$\n",
    "\n",
    "\\begin{align}\n",
    "    & bias(\\hat \\theta_m) = \\mathbb{E}[\\hat \\theta_m] - \\theta \\\\\n",
    "    \\Rightarrow & \\frac{1}{m} \\sum_{i=1}^{m} \\mathbb{E}[x^{(i)}] - \\theta \\\\\n",
    "    \\Rightarrow & \\frac{1}{m} \\sum_{i=1}^{m} (0*\\theta^0*(1-\\theta)^{1-0} + 1*\\theta^1*(1-\\theta)^{1-1}) - \\theta \\\\\n",
    "    \\Rightarrow & \\frac{1}{m} \\sum_{i=1}^{m} \\theta - \\theta \\\\\n",
    "    \\Rightarrow & \\theta - \\theta = 0 \\\\\n",
    "\\end{align}\n",
    "\n",
    "> 期望值等於值乘機率和$x^{(i)}$等於零或一\n",
    "\n",
    "Since $bias(\\hat \\theta) = 0$, we say that our estimator, __mean of the training samples__, $\\hat \\theta$ is unbiased."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Example: Bias of mean estimator of Gaussian Distribution\n",
    "Consider a set of m samples that are independently and identically distributed (i.i.d) drawn from a Gaussian distribution (population unknow) with mean equals to $\\mu$ and variance equals to $\\sigma^2$ $$P(x^{(i)};\\mu,\\sigma^2) = \\sqrt{\\frac{1}{2 \\pi \\sigma^{2}}} exp(- \\frac{1}{2 \\sigma^2}(x^{(i)} - \\mu)^2)$$\n",
    "\n",
    "A common estimator of the Gaussian mean parameter is known as the __sample mean__ \n",
    "$$\\hat \\mu_m = \\frac{1}{m} \\sum_{i=1}^{m} x^{(i)}$$\n",
    "\n",
    "\\begin{align}\n",
    "    bias(\\hat \\mu_m) = & \\mathbb{E}[\\hat \\mu_m] - \\mu \\\\\n",
    "    = & \\frac{1}{m} \\sum_{i=1}^{m} \\mathbb{E}[x^{(i)}] - \\mu \\\\\n",
    "    = & \\frac{1}{m} \\sum_{i=1}^{m} \\mu -\\mu = 0 \\\\\n",
    "\\end{align}\n",
    "\n",
    "The __sample mean__ is an __unbiased estimator__ of Gaussian mean parameter. Sample mean equals to the real Gaussian distribution mean. \n",
    "\n",
    "$$\\mathbb{E}[\\hat \\mu_m] = \\mu$$"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Example: Bias of variance estimator of Gaussian Distribution\n",
    "The first estimator of variance we consider is known as the __sample variance__\n",
    "$$\\hat \\sigma_m^2 = \\frac{1}{m} \\sum_{i=1}^{m} (x^{(i)}-\\hat \\mu_m)^2 $$ \n",
    "\n",
    "\\begin{align}\n",
    "    bias(\\hat \\sigma_m^2) = & \\mathbb{E}[\\hat \\sigma_m^2] - \\sigma^2 \\\\\n",
    "    = & \\mathbb{E}(\\frac{1}{m} \\sum_{i=1}^{m} (x^{(i)} - \\hat \\mu_m)^2) - \\sigma^2  \\\\\n",
    "    = & \\frac{1}{m} \\sum_{i=1}^{m}[ \\mathbb{E}(x^{(i)^2}) - 2\\mathbb{E}(x^{(i)}\\hat \\mu_m) + \\mathbb{E}(\\hat \\mu_m^2)]- \\sigma^2 \\\\\n",
    "\\end{align}\n",
    "\n",
    "> $$\\mathbb{E}[x_p x_q] = \\mathbb{E}[x_p] \\mathbb{E}[x_q] = \\mu^2, \\; p \\neq q$$ \n",
    "> $$\\mathbb{E}[x_p x_q] = \\mathbb{E}[x_p^2] = \\sigma^2 + \\mu^2, \\; p = q$$ \n",
    "\n",
    "> Since we have m samples, the possibility of getting the same sample is 1/m\n",
    "\n",
    "> $$\\mathbb{E}[x_j \\hat \\mu_m] = \\frac{(m-1) \\mu^2 + (\\sigma^2 + \\mu^2) }{m}$$ \n",
    "\n",
    "> Since we have $m^2$ terms, the possibility of getting the same sample is $m^2-m$\n",
    "\n",
    "> $$\\mathbb{E}[\\hat \\mu_m^2] = \\frac{(m^2-m)\\mu^2 + m(\\sigma^2+\\mu^2)}{m^2}$$ \n",
    "\n",
    "\\begin{align}\n",
    "    = & \\frac{1}{m} \\sum_{i=1}^{m}[ \\sigma^2 + \\mu^2 - 2(\\frac{(m-1) \\mu^2 + (\\sigma^2 + \\mu^2) }{m}) + \\frac{(m^2-m)\\mu^2 + m(\\sigma^2+\\mu^2)}{m^2}]- \\sigma^2 \\\\\n",
    "    = & [\\sigma^2 + \\mu^2 - 2(\\frac{(m-1) \\mu^2 + (\\sigma^2 + \\mu^2) }{m}) + \\frac{(m^2-m)\\mu^2 + m(\\sigma^2+\\mu^2)}{m^2}]- \\sigma^2 \\\\\n",
    "    = & \\frac{m-1}{m} \\sigma^2 - \\sigma^2 = -\\frac{\\sigma^2}{m} \\\\\n",
    "\\end{align}\n",
    "\n",
    "We conclude that the bias of $\\hat \\sigma_m^2$ is $-\\frac{\\sigma^2}{m}$. Therefore,\n",
    "the __sample variance__ is a __biased estimator__.\n",
    "\n",
    "We have two estimators: one is biased and the other is not. While unbiased estimators are clearly desirable, they are not always the “best” estimators."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The second estimator of variance we consider is known as the __unbiased sample variance estimator__\n",
    "\n",
    "$$\\tilde \\sigma_m^2 = \\frac{1}{m-1} \\sum_{i=1}^m (x^{(i)} i \\hat \\mu_m )^2 $$\n",
    "\n",
    "\\begin{align}\n",
    "    bias(\\tilde \\sigma_m^2) = & \\mathbb{E}[\\tilde \\sigma_m^2] - \\sigma^2 \\\\\n",
    "    = & \\mathbb{E}(\\frac{1}{m-1} \\sum_{i=1}^{m} (x^{(i)} - \\hat \\mu_m)^2) - \\sigma^2 \\\\\n",
    "    = & \\frac{m}{m-1} \\mathbb{E}[\\hat \\sigma_m^2] - \\sigma^2 \\\\\n",
    "    = & \\frac{m}{m-1} (\\frac{m-1}{m} \\sigma^2) - \\sigma^2 = 0 \\\\\n",
    "\\end{align}\n",
    "\n",
    "The __unbiased sample variance__ estimator is an unbiased estimator of Gaussian variance parameter. Unbiased sample variance equals to the real Gaussian distribution variance.\n",
    "\n",
    "$$\\mathbb{E}[\\tilde \\sigma_m^2] = \\sigma^2$$"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 5.4.3 Variance and Standard Error \n",
    "Another property of the estimator that we might want to consider is how much we expect it to vary as a function of the data sample. The __variance of an estimator__ is simply the variance $$Var(\\hat \\theta)$$\n",
    "\n",
    "The square root of the variance is called the __standard error__, denoted $SE(\\hat \\theta)$.\n",
    "\n",
    "The __variance or the standard error of an estimator__ provides a measure of _how we would expect the estimate we compute from data to vary as we independently resample the dataset from the underlying data generating process._\n",
    "\n",
    "The standard error of the mean is given by \n",
    "\n",
    "\\begin{align}\n",
    "    SE(\\hat \\mu_m) = & \\sqrt{ Var[\\frac{1}{m} \\sum_{i=1}^{m} x^{(i)}]} \\\\\n",
    "    = & \\sqrt{ \\frac{1}{m^2} Var[\\sum_{i=1}^{m} x^{(i)}]} \\\\\n",
    "    = & \\sqrt{ \\frac{1}{m^2} m \\sigma^2} \\\\\n",
    "    = & \\frac{\\sigma}{\\sqrt{m}} \\\\\n",
    "\\end{align}\n",
    "\n",
    "where $\\sigma^2$ is the true variance of the samples $x^{(i)}$ \n",
    "\n",
    "```\n",
    "The standard error of the sample mean is an estimate of how far the sample mean is likely to be from the population mean\n",
    "```\n",
    "\n",
    "The standard error is often estimated by using an estimate of $\\sigma$. Unfortunately, neither the square root of the sample variance nor the square root of the unbiased estimator of the variance provide an unbiased estimate of the standard deviation. Both approaches tend to underestimate the true standard deviation, but are still used in practice.\n",
    "\n",
    "The __standard error of the mean__ is very useful in machine learning experiments. We often __estimate the generalization error__ by computing the __sample mean of the error__ on the __test set__. The number of examples in the test set determines the accuracy of this estimate. Taking advantage of the central limit theorem, which tells us that __the mean will be approximately distributed with a normal distribution__, we can use the standard error to compute the probability that the true expectation falls in any chosen interval.\n",
    "\n",
    "In machine learning experiments, it is common to say that algorithm A is _better than_ algorithm B if the upper bound of the 95% confidence interval for the error of algorithm A is less than the lower bound of the 95% confidence interval for the error of algorithm B"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Example: Variance of mean estimator of Bernoulli Distribution\n",
    "Consider a set of m samples that are independently and identically distributed (i.i.d) according to a Bernoulli distribution with mean $\\theta$: \n",
    "$$P(x^{(i)};\\theta) = \\theta^{x^{(i)}} (1-\\theta)^{(1-x^{(i)})} $$\n",
    "A common estimator for the $\\theta$ parameter of this distribution is the __mean of the training samples__: \n",
    "$$\\hat \\theta_m = \\frac{1}{m} \\sum_{i=1}^{m} x^{(i)}$$\n",
    "\n",
    "This time we are interested in computing the variance of the estimator $\\hat \\theta_m$\n",
    "\n",
    "\\begin{align}\n",
    "    Var(\\hat \\theta_m) = & Var(\\frac{1}{m} \\sum_{i=1}^{m} x^{(i)}) \\\\\n",
    "    = & \\frac{1}{m^2} \\sum_{i=1}^{m} Var(x^{(i)}) \\\\\n",
    "    = & \\frac{1}{m^2} \\sum_{i=1}^{m} \\theta(1-\\theta) \\\\\n",
    "    = & \\frac{1}{m^2} m\\theta(1-\\theta) \\\\\n",
    "    = & \\frac{1}{m} \\theta(1-\\theta) \\\\\n",
    "\\end{align}\n",
    "\n",
    "The variance of the estimator decreases as a function of m, the number of examples in the dataset. This is a common property of popular estimators. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 5.4.4 Trading off Bias and Variance to Minimize Mean Squared Error\n",
    "```\n",
    "Bias and variance measure two different sources of error in an estimator. Bias measures the expected deviation from the true value of the function or parameter. Variance on the other hand, provides a measure of the deviation from the expected estimator value that any particular sampling of the data is likely to cause.\n",
    "```\n",
    "\n",
    "Imagine that we are interested in approximating the function shown and we are only offered the choice between a model with large bias and one that suffers from large variance. How do we choose between them?\n",
    "\n",
    "The most common way to negotiate this trade-off is to use __cross-validation__. Alternatively, we can also compare the __mean squared error (MSE) of the estimates__: \n",
    "\n",
    "\\begin{align}\n",
    "    MSE = & \\mathbb{E}[(\\hat \\theta_m - \\theta)^2] \\\\\n",
    "    = & \\mathbb{E}(\\hat \\theta_m^2 -2\\hat \\theta_m \\theta + \\theta^2) \\\\\n",
    "    = & \\mathbb{E}(\\hat \\theta_m)^2 -2 \\mathbb{E}(\\hat \\theta_m) \\theta + \\theta^2 + \\mathbb{E}(\\hat \\theta_m^2) - \\mathbb{E}(\\hat \\theta_m)^2 \\\\\n",
    "    = & (\\mathbb{E}(\\hat \\theta_m) - \\theta)^2 + (\\mathbb{E}(\\hat \\theta_m^2) - \\mathbb{E}(\\hat \\theta_m)^2) \\\\\n",
    "    = & bias(\\hat \\theta_m)^2 + Var(\\hat \\theta_m) \\\\\n",
    "\\end{align}\n",
    "\n",
    "The MSE measures the overall expected deviation—in a squared error sense between the estimator and the true value of the parameter $\\theta$. Evaluating the MSE incorporates __both the bias and the variance.__\n",
    "\n",
    "```\n",
    "The relationship between bias and variance is tightly linked to the machine learning concepts of capacity, underfitting and overfitting. \n",
    "```\n",
    "\n",
    "```\n",
    "In the case where generalization error is measured by the MSE (where bias and variance are meaningful components of generalization error), increasing capacity tends to increase variance and decrease bias.\n",
    "```"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 5.4.5 Consistency\n",
    "We usually wish that, as the number of data points m in our dataset increases, our point estimates converge to the true value of the corresponding parameters known as __consistency.__\n",
    "\n",
    "Consistency ensures that the bias induced by the estimator diminishes as the number of data examples grows. However, the reverse is not true—asymptotic __unbiasedness does not imply consistency.__\n",
    "\n",
    "For example, consider estimating the mean parameter $\\mu$ of a normal distribution $N (x;\\mu,\\sigma^2)$, with a dataset consisting of m samples: $\\{x^{(1)}, . . . , x^{(m)} \\}$. We could use the first sample $x^{(1)}$ of the dataset as an unbiased estimator: $ \\hat \\theta = x^{(1)} $. In that case, $\\mathbb{E}(\\theta _m) = \\theta$ so the estimator\n",
    "is unbiased no matter how many data points are seen. This, of course, implies that the estimate is asymptotically unbiased. However, this is not a consistent estimator as it is not the case that $\\theta_m \\rightarrow \\theta$ as $m \\rightarrow \\infty$."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 5.5 Maximum Likelihood Estimation\n",
    "Rather than guessing that some function might make a good estimator and then analyzing its bias and variance, we would like to have some principle from which we can _derive specific functions that are good estimators for different models._\n",
    "The most common such principle is the __maximum likelihood principle__.\n",
    "\n",
    "Consider a set of m examples $X = \\{x^{(1)}, . . . , x^ {(m)}\\}$ drawn independently from the true but unknown data generating distribution $p_{data}(x)$.\n",
    "\n",
    "Let $p_{model}(x;\\theta)$ be a parametric family of probability distributions over the same space indexed by $\\theta$. In other words, $p_{model}(x;\\theta)$ maps any configuration x to a real number estimating the true probability $p_{data}(x)$.\n",
    "\n",
    "The maximum likelihood estimator for $\\theta$ is then defined as \n",
    "\n",
    "\\begin{align}\n",
    "    \\theta_{ML} = & arg \\max_{\\theta} p_{model}(X;\\theta) \\\\\n",
    "    = & arg \\max_{\\theta} \\prod_{i=1}^m p_{model}(x^{(i)};\\theta) \\\\\n",
    "\\end{align}\n",
    "\n",
    "We observe that taking the logarithm of the likelihood does not change its arg max but does conveniently transform a product into a sum.\n",
    "\n",
    "$$\n",
    "\\theta_{ML} = arg \\max_{\\theta} \\sum_{i=1}^m \\log p_{model}(x^{(i)};\\theta)\n",
    "$$\n",
    "\n",
    "Because the arg max does not change when we rescale the cost function, we can divide by m to obtain a version of the criterion that is expressed as __an expectation with respect to the empirical distribution__ $\\hat p_{data}$ defined by the training data:\n",
    "\n",
    "$$\n",
    "\\theta_{ML} = arg \\max_{\\theta} \\mathbb{E}_{x \\sim \\hat p_{data}} \\log p_{model}(x;\\theta)\n",
    "$$\n",
    "\n",
    "One way to interpret maximum likelihood estimation is to view it as minimizing the dissimilarity between the empirical distribution $\\hat p_{data}$ defined by the training\n",
    "set and the model distribution, with the degree of dissimilarity between the two measured by the KL divergence. The KL divergence is given by\n",
    "\n",
    "$$\n",
    "D_{KL} (\\hat p_{data} || p_{model}) = \\mathbb{E}_{x \\sim \\hat p_{data}} [ \\log \\hat p_{data}(x) - \\log p_{model}(x)]\n",
    "$$\n",
    "\n",
    "The term on the left is a function only of the data generating process, not the model. This means when we train the model to minimize the KL divergence, we need only minimize \n",
    "\n",
    "$$\n",
    "\\mathbb{E}_{x \\sim \\hat p_{data}} - \\log p_{model}(x)\n",
    "$$\n",
    "\n",
    "We can thus _see maximum likelihood as an attempt to make the model distribution match the empirical distribution $\\hat p_{data}$_. Ideally, we would like to match the true data generating distribution $p_{data}$, but we have no direct access to this distribution.\n",
    "\n",
    "In software, we often phrase both as minimizing a cost function. Maximum likelihood thus becomes __minimization of the negative log-likelihood (NLL)__, or equivalently, __minimization of the cross entropy__. The perspective of maximum likelihood as minimum KL divergence becomes helpful in this case because the KL divergence has a known minimum value of zero. The negative log-likelihood can actually become negative when x is real-valued."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 5.5.1 Conditional Log-Likelihood and Mean Squared Error\n",
    "The maximum likelihood estimator can readily be generalized to the case where\n",
    "our goal is to estimate a conditional probability P(y | x ; θ)\n",
    "\n",
    "This is actually the most common situation because it forms the basis for\n",
    "most supervised learning. \n",
    "\n",
    "If X represents all our inputs and Y all our observed targets, then the conditional maximum likelihood estimator is \n",
    "$$\\theta_{ML} = arg \\max_{\\theta} P(Y|X;\\theta)$$\n",
    "\n",
    "If the examples are assumed to be i.i.d., then this can be decomposed into\n",
    "$$\\theta_{ML} = arg \\max_{\\theta} \\sum_{i=1}^{m} \\log P(y^{(i)}|x^{(i)};\\theta)$$\n",
    "\n",
    "#### Example: Linear Regression as Maximum Likelihood\n",
    "Instead of producing a single prediction $\\hat y$, we now think of the model as producing a conditional distribution p(y | x). \n",
    "We can imagine that with an infinitely large training set, we might see several training examples with the same input value x but different values of y. \n",
    "\n",
    "The goal of the learning algorithm is now to fit the distribution p (y | x) to all of those different y values that are all compatible with x.\n",
    "\n",
    "We define $p(y | x) = N(y ; \\hat y(x;w) , \\sigma^2)$. The function $\\hat y(x; w)$ gives the prediction of the mean of the Gaussian. We assume that the variance is fixed to some constant $\\sigma^2$ chosen by the user.\n",
    "\n",
    "The __conditional log-likelihood__ is given by \n",
    "\n",
    "\\begin{align}\n",
    "    & \\sum_{i=1}^{m} \\log p(y^{(i)}|x^{(i)};\\theta) \\\\\n",
    "    = & -m \\log \\sigma - \\frac{m}{2} \\log(2 \\pi) - \\sum_{i=1}^{m} \\frac{|| \\hat y^{(i)} - y^{(i)}||^2}{2 \\sigma^2} \\\\\n",
    "\\end{align}\n",
    "\n",
    "> Assume P is a normal distribution. $$ P(y^{(i)};\\hat y^{(i)},\\sigma^2) = \\frac{1}{\\sqrt{2 \\pi \\sigma^2}} exp(-\\frac{{( y^{(i)} - \\hat y^{(i)} })^2 }{2 \\sigma^2})\n",
    "$$\n",
    "\n",
    "Comparing the log-likelihood with the mean squared error, \n",
    "$$\n",
    "MSE_{train} = \\frac{1}{m} \\sum_{i=1}^{m} || \\hat y^{(i)} - y^{(i)} ||^2\n",
    "$$\n",
    "We immediately see that maximizing the log-likelihood with respect to w yields\n",
    "the same estimate of the parameters w as does minimizing the mean squared error."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 5.5.2 Properties of Maximum Likelihood\n",
    "The main appeal of the __maximum likelihood estimator__ is that it can be shown to\n",
    "be the __best estimator asymptotically__, as the number of examples m → ∞, in terms\n",
    "of its rate of convergence as m increases.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 5.8 Unsupervised Learning Algorithms\n",
    "__Unsupervised learning__ refers to most attempts to extract information from a distribution that do not require human labor to annotate examples.\n",
    "\n",
    "A classic unsupervised learning task is to find the __“best” representation__ of the\n",
    "data. By ‘best’ we can mean different things, but generally speaking we are looking\n",
    "for a representation that preserves as much information about x as possible while\n",
    "obeying some penalty or constraint aimed at keeping the representation simpler or\n",
    "more accessible than x itself.\n",
    "\n",
    "There are multiple ways of defining a __simpler__ representation. Three of the\n",
    "most common include \n",
    "- __Lower dimensional representations__\n",
    "attempt to compress as much information about x as possible in a smaller representation.\n",
    "- __Sparse representations__\n",
    "embed the dataset into a representation whose entries are\n",
    "mostly zeroes for most inputs. The use of sparse representations typically requires\n",
    "increasing the dimensionality of the representation, so that the representation\n",
    "becoming mostly zeroes does not discard too much information. \n",
    "- __Independent representations__.\n",
    "attempt to disentangle the sources of variation underlying the data distribution such that the dimensions of the representation are statistically independent."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 5.8.1 Principal Components Analysis\n",
    "PCA learns a representation that has lower dimensionality than the original input. It also learns a representation whose elements have no linear correlation with each other.\n",
    "\n",
    "PCA learns an orthogonal, linear transformation of the data that projects an\n",
    "input x to a representation z. We can use PCA as a simple and effective __dimensionality reduction method__ that preserves as much of the information in the data as possible (again, as measured by least-squares reconstruction error).\n",
    "\n",
    "Let us consider the m × n dimensional design matrix X. We will assume that\n",
    "the data has a mean of zero, $\\mathbb{E}[x] = 0$. If this is not the case, the data can easily be centered by subtracting the mean from all examples in a preprocessing step.\n",
    "\n",
    "The __unbiased sample covariance matrix__ associated with X is given by:\n",
    "$$ Var[x] = \\frac{1}{m-1} X^TX\n",
    "$$\n",
    "\n",
    "PCA finds a representation (through linear transformation) $z = x^TW$ where $Var[z]$ is diagonal. (Prove later)\n",
    "\n",
    "From previous section, we saw that the principal components of a design matrix X are given by the eigenvectors of $X^TX$. \n",
    "\n",
    "$$\n",
    "X^TX = W \\Lambda W^T\n",
    "$$\n",
    "\n",
    "The principal components may also be obtained via the singular value decomposition. Let W be the right singular vectors in the decomposition $X=U \\Lambda W^T$\n",
    "\n",
    "We then recoverthe original eigenvector equation with W as the eigenvector basis:\n",
    "\n",
    "$$\n",
    "X^TX = (U \\Sigma W^T)^T (U \\Sigma W^T) = W \\Sigma^2 W^T \\\\\n",
    "where \\; \\Sigma^2 = \\Lambda\n",
    "$$\n",
    "\n",
    "Using the SVD of X, we can express the variance of X as:\n",
    "\n",
    "\\begin{align}\n",
    "    Var[x] = & \\frac{1}{m-1} X^TX \\\\\n",
    "    = & \\frac{1}{m-1} (U \\Sigma W^T)^T (U \\Sigma W^T) \\\\\n",
    "    = & \\frac{1}{m-1} W \\Sigma^T U^T U \\Sigma W^T \\\\\n",
    "    = & \\frac{1}{m-1} W \\Sigma^2 W^T \\\\\n",
    "\\end{align}\n",
    "\n",
    "If we take $z = x^T W$ , we can ensure that the covariance of z is diagonal as required:\n",
    "\n",
    "\\begin{align}\n",
    "    Var[z] = & \\frac{1}{m-1} Z^TZ \\\\\n",
    "    = & \\frac{1}{m-1} W^T X^T X W \\\\\n",
    "    = & \\frac{1}{m-1} W^T W \\Sigma^2 W^T W \\\\\n",
    "    = & \\frac{1}{m-1} \\Sigma^2 \\\\\n",
    "\\end{align}\n",
    "\n",
    "The above analysis shows that when we project the data x to z, via the linear transformation W, the resulting representation has a diagonal covariance matrix (as given by $\\Sigma^2$) which immediately implies that the __individual elements of z are\n",
    "mutually uncorrelated__. It is a simple example of a representation that attempts to _disentangle the unknown factors of\n",
    "variation_ underlying the data.\n",
    "\n",
    "In the case of PCA, this disentangling takes the form of finding __a rotation__ of the input space (described by W) that aligns the principal axes of variance with the basis of the new representation space associated with z.\n",
    "\n",
    "While correlation is an important category of dependency between elements of the data, we are also interested in __learning representations that disentangle more complicated forms of feature dependencies__. For this, we will need more than what can be done with a simple linear transformation."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 5.8.2 k-means Clustering"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 5.9 Stochastic Gradient Descent\n",
    "Stochastic gradient descent is an extension of the gradient descent algorithm. A recurring problem in machine learning is that large training sets are necessary for good generalization, but large training sets are also more computationally expensive.\n",
    "\n",
    "The cost function used by a machine learning algorithm often decomposes as __a sum over training examples of some per-example loss function (i.e. negative log-likelihood).__\n",
    "\n",
    "The insight of stochastic gradient descent is that the __gradient is an expectation.__\n",
    "\n",
    "The gradient of a cost function:\n",
    "$$\n",
    "g = \\nabla_{\\theta} J(\\theta) = \\frac{1}{m} \\sum_{i=1}^{m} \\nabla_{\\theta} L(x^{(i)},y^{(i)},\\theta)\n",
    "$$\n",
    "\n",
    "The __estimate of the gradient__ is formed as:\n",
    "$$\n",
    "g = \\frac{1}{m'} \\nabla_{\\theta} \\sum_{i=1}^{m'}  L(x^{(i)},y^{(i)},\\theta)\n",
    "$$\n",
    "where m' is the size of minibatch\n",
    "\n",
    "The expectation may be approximately estimated using a small set of samples.\n",
    "\n",
    "Specifically, on each step of the algorithm, we can __sample a minibatch of examples__ $B = \\{x^{(1)},...,x^{(m')} \\}$ drawn uniformly from the training set. \n",
    "\n",
    "Stochastic gradient descent has many important uses outside the context of deep learning. It is the main way to train large linear models on very large datasets. For a fixed model size, the cost per SGD update __does not depend on the training set size m.__"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 5.10 Building a Machine Learning Algorithm\n",
    "Nearly all deep learning algorithms can be described as particular instances of a fairly simple recipe: \n",
    "- Combine a specification of a dataset\n",
    "- A cost function\n",
    "- An optimization procedure and a model"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 5.11 Challenges Motivating Deep Learning\n",
    "How the challenge of generalizing to new examples becomes exponentially more difficult when working with high-dimensional data, and how the mechanisms used to achieve generalization in traditional machine learning are insufficient to learn complicated functions in high-dimensional spaces.\n",
    "\n",
    "Such spaces also often impose high computational costs. Deep learning was designed to overcome these and other obstacles."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 5.11.1 The Curse of Dimensionality\n",
    "Many machine learning problems become exceedingly difficult when the number of dimensions in the data is high. This phenomenon is known as the __curse of dimensionality__\n",
    "\n",
    "Of particular concern is that __the number of possible distinct configurations__ of a set of variables __increases exponentially__ as the number of variables increases.\n",
    "\n",
    "One challenge posed by the curse of dimensionality is a __statistical challenge__. A statistical challenge arises because the number of possible configurations of x is much larger than the number of training examples.\n",
    "\n",
    "Because in high-dimensional spaces the number of configurations is huge, much larger than our number of examples, a typical grid cell has no training example associated with it. How could we possibly say something meaningful about these new configurations?"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 5.11.2 Local Constancy and Smoothness Regularization\n",
    "In order to generalize well, machine learning algorithms need to be guided by prior beliefs about what kind of function they should learn.\n",
    "\n",
    "Throughout this book, we will describe how deep learning introduces additional (explicit and implicit) priors in order to reduce the generalization error on sophisticated tasks.\n",
    "\n",
    "Among the most widely used of these implicit “priors” is the __smoothness prior__ or __local constancy prior__. This prior states that the function we learn should not change very much within a small region.\n",
    "\n",
    "In other words, if we know a good answer for an input x (for example, if x is a labeled training example) then that answer is probably good in the neighborhood of x.\n",
    "\n",
    "If we have several good answers in some neighborhood we would combine them (by some form of averaging or interpolation) to produce an answer that agrees with as many of them as much as possible.\n",
    "\n",
    "__Decision trees__ also suffer from the limitations of exclusively smoothness-based learning because they break the input space into as many regions as there are leaves and use a separate parameter (or sometimes many parameters for extensions of decision trees) in each region. If the target function requires a tree with at least n leaves to be represented accurately, then at least n training examples are required to fit the tree.\n",
    "\n",
    "The smoothness assumption and the associated non-parametric learning algorithms work extremely well so long as there are enough examples for the learning algorithm to observe high points on most peaks and low points on most valleys of the true underlying function to be learned.\n",
    "\n",
    "In high dimensions, even a very smooth function can change smoothly but in a different way along each dimension. If the function additionally behaves differently in different regions, it can become extremely complicated to describe with a set of training examples. \n",
    "\n",
    "If the function is complicated (we want to distinguish a huge number of regions compared to the number of examples), is there any hope to generalize well?\n",
    "\n",
    "- Whether it is possible to represent a complicated function efficiently ? Yes\n",
    "- Whether it is possible for the estimated function to generalize well to new inputs ? Yes. \n",
    "\n",
    "We introduce some __dependencies between the regions via additional assumptions__ about the underlying data generating distribution. In this way, we can actually generalize non-locally.\n",
    "\n",
    "AI tasks have structure that is much too complex to be limited to simple, manually specified properties such as periodicity, so we want learning algorithms that embody more general-purpose assumptions.\n",
    "\n",
    "The core idea in deep learning is that we assume that the __data was generated by the composition of factors or features__, potentially at __multiple levels in a hierarchy__."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 5.11.3 Manifold Learning\n",
    "A __manifold__ is a connected region. Mathematically, it is a set of points, associated with a neighborhood around each point.\n",
    "\n",
    "Many machine learning problems seem hopeless if we expect the machine learning algorithm to learn functions with interesting variations across all of $R^n$\n",
    "\n",
    "Manifold learning algorithms surmount this obstacle by assuming that most of $R^n$ consists of invalid inputs, and that interesting inputs occur only along a collection of manifolds containing a small subset of points, with interesting variations in the output of the learned function occurring only along directions that lie on the manifold. \n",
    "\n",
    "The assumption that the __data lies along a low-dimensional manifold may NOT always be correct or useful__. The evidence in favor of this assumption consists of two categories of observations.\n",
    "\n",
    "- The first observation: the probability distribution over images, text strings, and sounds that occur in real life is __highly concentrated__. If you generate a document by picking letters uniformly at random, what is the probability that you will get a meaningful English-language text? The distribution of natural language sequences occupies a very small volume in the total space of sequences of letters.\n",
    "\n",
    "- The second argument in favor of the manifold hypothesis is that we can also __imagine such neighborhoods and transformations__, at least informally. In the case of images, we can certainly think of many possible transformations that allow us to trace out a manifold in image space: we can gradually dim or brighten the lights, gradually move or rotate objects in the image, gradually alter the colors on the surfaces of objects, etc."
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
